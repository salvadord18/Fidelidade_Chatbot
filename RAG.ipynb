{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc12e8e-8a1c-43dd-8c8f-7a7ebd9b14f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T14:07:34.828792Z",
     "iopub.status.busy": "2025-05-11T14:07:34.828433Z",
     "iopub.status.idle": "2025-05-11T14:07:34.862009Z",
     "shell.execute_reply": "2025-05-11T14:07:34.860851Z",
     "shell.execute_reply.started": "2025-05-11T14:07:34.828762Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfitz\u001b[39;00m \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtext_splitter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfaiss\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "import fitz \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773fa5f2-4330-4d1c-a090-5cf379771262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T14:07:05.862399Z",
     "iopub.status.busy": "2025-05-11T14:07:05.862037Z",
     "iopub.status.idle": "2025-05-11T14:07:34.826609Z",
     "shell.execute_reply": "2025-05-11T14:07:34.825572Z",
     "shell.execute_reply.started": "2025-05-11T14:07:05.862369Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/bcwds2/lib/python3.13/site-packages (from sentence_transformers) (4.67.1)\n",
      "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached sentence_transformers-4.0.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached sentence_transformers-4.0.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is still looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-2.2.1.tar.gz (84 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-2.1.0.tar.gz (78 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tokenizers>=0.10.3 (from sentence_transformers)\n",
      "  Using cached tokenizers-0.21.1-cp39-abi3-macosx_10_12_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-2.0.0.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.2.1.tar.gz (80 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.2.0.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.1.1.tar.gz (81 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.1.0.tar.gz (78 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.0.4.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.0.3.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.0.2.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.0.1.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-1.0.0.tar.gz (74 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.4.1.2.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.4.1.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.4.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.4.0.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.9.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<3.6.0,>=3.1.0 (from sentence_transformers)\n",
      "  Using cached transformers-3.5.1-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.3.8.tar.gz (66 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<3.4.0,>=3.1.0 (from sentence_transformers)\n",
      "  Using cached transformers-3.3.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.3.7.2.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.7.1.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.7.tar.gz (59 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.6.tar.gz (62 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<3.2.0,>=3.1.0 (from sentence_transformers)\n",
      "  Using cached transformers-3.1.0-py3-none-any.whl.metadata (49 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.3.5.1.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==3.0.2 (from sentence_transformers)\n",
      "  Using cached transformers-3.0.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.3.5.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.4.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.3.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.2.tar.gz (65 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.1.tar.gz (64 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.3.0.tar.gz (61 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.2.6.2.tar.gz (60 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==2.11.0 (from sentence_transformers)\n",
      "  Using cached transformers-2.11.0-py3-none-any.whl.metadata (45 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.2.6.1.tar.gz (55 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.2.5.1.tar.gz (52 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==2.3.0 (from sentence_transformers)\n",
      "  Using cached transformers-2.3.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.2.5.tar.gz (49 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.2.4.1.tar.gz (49 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==2.2.1 (from sentence_transformers)\n",
      "  Using cached transformers-2.2.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.2.4.tar.gz (49 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.2.3.tar.gz (45 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-transformers==1.1.0 (from sentence_transformers)\n",
      "  Using cached pytorch_transformers-1.1.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.2.2.tar.gz (44 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.2.1.tar.gz (42 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-transformers==1.0.0 (from sentence_transformers)\n",
      "  Using cached pytorch_transformers-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-0.2.0.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Using cached sentence-transformers-0.1.0.tar.gz (35 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[31mERROR: Cannot install sentence-transformers==0.1.0, sentence-transformers==0.2.0, sentence-transformers==0.2.1, sentence-transformers==0.2.2, sentence-transformers==0.2.3, sentence-transformers==0.2.4, sentence-transformers==0.2.4.1, sentence-transformers==0.2.5, sentence-transformers==0.2.5.1, sentence-transformers==0.2.6.1, sentence-transformers==0.2.6.2, sentence-transformers==0.3.0, sentence-transformers==0.3.1, sentence-transformers==0.3.2, sentence-transformers==0.3.3, sentence-transformers==0.3.4, sentence-transformers==0.3.5, sentence-transformers==0.3.5.1, sentence-transformers==0.3.6, sentence-transformers==0.3.7, sentence-transformers==0.3.7.1, sentence-transformers==0.3.7.2, sentence-transformers==0.3.8, sentence-transformers==0.3.9, sentence-transformers==0.4.0, sentence-transformers==0.4.1, sentence-transformers==0.4.1.1, sentence-transformers==0.4.1.2, sentence-transformers==1.0.0, sentence-transformers==1.0.1, sentence-transformers==1.0.2, sentence-transformers==1.0.3, sentence-transformers==1.0.4, sentence-transformers==1.1.0, sentence-transformers==1.1.1, sentence-transformers==1.2.0, sentence-transformers==1.2.1, sentence-transformers==2.0.0, sentence-transformers==2.1.0, sentence-transformers==2.2.0, sentence-transformers==2.2.1, sentence-transformers==2.2.2, sentence-transformers==2.3.0, sentence-transformers==2.3.1, sentence-transformers==2.4.0, sentence-transformers==2.5.0, sentence-transformers==2.5.1, sentence-transformers==2.6.0, sentence-transformers==2.6.1, sentence-transformers==2.7.0, sentence-transformers==3.0.0, sentence-transformers==3.0.1, sentence-transformers==3.1.0, sentence-transformers==3.1.1, sentence-transformers==3.2.0, sentence-transformers==3.2.1, sentence-transformers==3.3.0, sentence-transformers==3.3.1, sentence-transformers==3.4.0, sentence-transformers==3.4.1, sentence-transformers==4.0.0, sentence-transformers==4.0.1, sentence-transformers==4.0.2 and sentence-transformers==4.1.0 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h\n",
      "The conflict is caused by:\n",
      "    sentence-transformers 4.1.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 4.0.2 depends on torch>=1.11.0\n",
      "    sentence-transformers 4.0.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 4.0.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.4.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.4.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.3.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.3.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.2.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.2.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.1.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.1.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.0.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.0.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.7.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.6.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.6.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.5.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.5.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.4.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.3.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.3.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.2.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.2.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.2.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.1.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.0.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.2.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.2.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.1.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.1.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.4 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.3 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.3.9 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.3.8 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7.2 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.6 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.5.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.5 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.4 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.3 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.2 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.0 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.6.2 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.6.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.5.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.5 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.4.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.4 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.3 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.2 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.0 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.1.0 depends on torch>=1.0.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b21ec325-f3fc-496d-b33b-78865da31807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-11T14:05:26.532255Z",
     "iopub.status.busy": "2025-05-11T14:05:26.531911Z",
     "iopub.status.idle": "2025-05-11T14:05:26.562898Z",
     "shell.execute_reply": "2025-05-11T14:05:26.561370Z",
     "shell.execute_reply.started": "2025-05-11T14:05:26.532229Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RecursiveCharacterTextSplitter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m         text += page.get_text()\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m splitter = \u001b[43mRecursiveCharacterTextSplitter\u001b[49m(chunk_size=\u001b[32m500\u001b[39m, chunk_overlap=\u001b[32m50\u001b[39m)\n\u001b[32m      9\u001b[39m chunks = splitter.split_text(extracted_text)\n\u001b[32m     13\u001b[39m model = SentenceTransformer(\u001b[33m\"\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'RecursiveCharacterTextSplitter' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    doc = fitz.open(file_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_text(extracted_text)\n",
    "\n",
    "\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = model.encode(chunks)\n",
    "\n",
    "\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "query = \"What is the main point of the document?\"\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "D, I = index.search(np.array(query_embedding), k=5)\n",
    "retrieved_chunks = [chunks[i] for i in I[0]]\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "context = \"\\n\".join(retrieved_chunks)\n",
    "prompt = f\"Answer the question based on the context:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\"\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")\n",
    "\n",
    "answer = response['choices'][0]['message']['content']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b436f07-0b90-40bd-ae29-336eb1bd9fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bcwds2",
   "language": "python",
   "name": "bcwds2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
